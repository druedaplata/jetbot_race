{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conociendo la JETBOT\n",
    "\n",
    "<img src=\"images/jetbot.jpeg\" width=50%>\n",
    "\n",
    "1. Jetson Nano, dispositivo de cómputo de bajo consumo con GPU integrada.\n",
    "\n",
    "2. Camara, que servirá de entrada a la aplicación.\n",
    "\n",
    "3. PioLed, que muestra información del sistema operativo y la ip del equipo (parte de atrás).\n",
    "\n",
    "4. Motor para el movimiento de las llantas.\n",
    "\n",
    "5. Batería de 5V y 3A.\n",
    "\n",
    "\n",
    "## Accediendo al Equipo\n",
    "\n",
    "1. Conecte el motor y la Jetson Nano a la batería.\n",
    "\n",
    "\n",
    "2. Espere a que la PioLed encienda e ingrese a la dirección mostrada y el puerto 8888.\n",
    "\n",
    "    - Por ejemplo, 192.168.1.7:8888\n",
    "    - La contraseña es *jetbot*\n",
    "    \n",
    "    \n",
    "3. Abra un nuevo *notebook* en la jetbot y siga las instrucciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movimientos Básicos\n",
    "\n",
    "La JetBot tiene 5 acciones básicos para el control del equipo:\n",
    "\n",
    "1. forward, mover hacia adelante.\n",
    "2. backward, mover hacia atrás.\n",
    "3. left, girar a la izquierda.\n",
    "4. right, girar a la derecha.\n",
    "5. stop, detener el motor.\n",
    "\n",
    "Para acceder a estos movimientos es necesario importar la clase Robot desde Jetbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia de la clase Robot, para acceder a el manejo del robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejar el robot\n",
    "\n",
    "**<font color='red'>ADVERTENCIA #1: </font>** LOS SIGUIENTES COMANDOS MUEVEN EL ROBOT, ASEGURESE QUE EL ROBOT TIENE ESPACIO LIBRE.\n",
    "\n",
    "\n",
    "**<font color='red'>ADVERTENCIA #2: </font>** EL ROBOT ES MUY RÁPIDO, SIEMPRE ASEGURESE DE AJUSTAR LA VELOCIDAD SOLO AL 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El robot gira hacia la izquierda sin detenerse\n",
    "robot.left(speed=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos detener el robot\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos que el robot se mueva solo por poco tiempo podemos usar la función **sleep** del paquete **time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.right(speed=0.3)\n",
    "time.sleep(2)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinando los movimientos básicos y la función **sleep**, podemos generar movimientos mas complejos para el movimiento del carro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_turn():\n",
    "    robot.left(speed=0.3)\n",
    "    time.sleep(2)\n",
    "    robot.forward(speed=0.3)\n",
    "    time.sleep(2)\n",
    "    robot.stop()\n",
    "    \n",
    "u_turn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceder a la cámara\n",
    "\n",
    "Podemos acceder a la cámara usando otras Clases que proporciona JETBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "# Creamos una instancia de la cámara, para acceder a esta.\n",
    "camera = Camera.insance(width=224, height=224)\n",
    "# Creamos una 'imagen' en notebook para mostrar lo que observa la cámara\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "# Enlazamos la información de la cámara con la imagen creada\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "# Mostramos la imagen en el notebook\n",
    "display(widgets.HBox([image]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimente por un tiempo con los comandos básicos, y apague la JetBot para ahorrar energía.\n",
    "\n",
    "Pidale ayuda a un instructor.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "<img src=\"images/dl_context.png\" width=70%>\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/ml_vs_dl.png\">\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/cnn_feature_hierarchy.png\">\n",
    "\n",
    "\n",
    "## Cómo funciona el deep learning?\n",
    "\n",
    "\n",
    "<img src=\"images/dl.png\" width=70%>\n",
    "  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Razones para la popularidad del Deep Learning\n",
    "\n",
    "### 1. Aparición de enormes conjuntos de datos.\n",
    "\n",
    "    - Datos Etiquetados ---> Aprendizaje Supervisado\n",
    "    - Datos No Etiquetados ---> Aprendizaje No Supervisado\n",
    "    - Algunos Datos Etiquetados ---> Aprendizaje Semi-Supervisado\n",
    "\n",
    "<img src=\"images/datasets_sample.jpeg\">\n",
    "\n",
    "### 2. Computación masivamente paralela con GPUs.\n",
    "\n",
    "ILSVRC = Imagenet Large Scale Visual Recognition Competition\n",
    "\n",
    "<img src=\"images/imagenet_progress.png\">\n",
    "\n",
    "### 3. Desarrollo de Frameworks de DL.\n",
    "\n",
    "Para la competencia usaremos el framework Pytorch\n",
    "\n",
    "<img src=\"images/dl_frameworks.jpg\" width=70%>\n",
    "\n",
    "### 4. Investigación en arquitecturas de redes neuronales y funciones de activación.\n",
    "\n",
    "Para la competencia usaremos Alexnet\n",
    "\n",
    "<img src=\"images/dl_architectures.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Flujo de Trabajo de un proyecto en Deep Learning\n",
    "\n",
    "<img src=\"images/dl_workflow.jpeg\">\n",
    "\n",
    "## Ejemplo: Evitar Colisiones con la JetBot\n",
    "\n",
    "Vamos a intentar resolver este problema usando deep learning, la jetson nano y el sensor de la cámara.\n",
    "\n",
    "\n",
    "### Paso 1: Obtener Datos\n",
    "\n",
    "El robot está limitado a la información que obtiene desde la camara, desde este punto de vista necesitamos crear una \"burbuja de seguridad\" al rededor del robot, para evitar que entre en escenarios donde se golpee.\n",
    "\n",
    "Tenemos entonces dos estados para el robot:\n",
    "\n",
    "1. **blocked:** El robot tiene algún obstaculo de frente por lo cual debe girar y buscar otro camino.\n",
    "\n",
    "2. **free:** El roboto puede avanzar libremente.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/free.jpeg\"></td>\n",
    "        <td><img src=\"images/blocked.jpeg\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**<font color='green'>RECOMENDACIÓN #1: </font>** Tome videos con el celular teniendo en cuenta la perspectiva del robot, para ambos estados. Recuerde las dimensiones del robot y los diferentes obstaculos que puede tener (puertas, sillas, zapatos, otros jetbot).\n",
    "\n",
    "**<font color='green'>RECOMENDACIÓN #2: </font>** Tome video donde el camino este libre todo el tiempo, tome videos cortos donde el camino esté bloqueado todo el tiempo, trate de no mezclar los dos casos para que sea mas fácil crear el dataset de imágenes.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Paso 2: Limpiar, preparar y manipular los datos.\n",
    "\n",
    "Una vez terminada la obtención de los videos, es necesario crear el dataset de imágenes en los dos estados que tiene nuestro equipo. Para obtener las imágenes que usaremos para el entrenamiento necesitamos separar los **frames** de los videos y guardarlas en imágenes.\n",
    "\n",
    "Cree un directorio llamado **dataset** y en este dos subdirectorios llamados **free** y **blocked**.\n",
    "\n",
    "Suba los videos a su directorio local en Guane, y desde la terminal en notebook ejecute el siguiente comando.\n",
    "\n",
    "```bash\n",
    "ffmpeg -i video.mp4 -vf fps=1 img_%04d.jpg -hide_banner\n",
    "```\n",
    "\n",
    "- **video.mp4**, es la ruta al video creado\n",
    "    \n",
    "- **-vf fps=1**, guardamos un frame por cada segundo de video\n",
    "\n",
    "- **img_%04d.jpg**, es un patrón para guardar cada imagen con un número diferente de salida\n",
    "\n",
    "\n",
    "Las imágenes obtenidas desde los videos **free** deben guardarse en la carpeta **free**, las imágenes de los videos **blocked** deben guardarse en la carpeta **blocked**.\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paso 3: Entrenar el modelo\n",
    "\n",
    "Usaremos el framework *Pytorch* para entrenar el modelo para nuestras dos clases (blocked, free).\n",
    "\n",
    "Copiamos el siguiente código al notebook en Guane, y analizamos los comentarios antes de ejecutarlo. \n",
    "\n",
    "**<font color='green'>RECOMENDACIÓN #3: </font>** Analizar los comentarios y entender este código puede darles una gran ventaja en la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el framework y las utilidades necesarias\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Creamos la instancia 'dataset' para acceder a las imágenes,\n",
    "# Componemos una secuencia de transformaciones para virtualmente aumentar la cantidad de los datos.\n",
    "#     - ColorJitter, modifica la luz, contraste e iluminación de la imagen por un porcentaje.\n",
    "#     - Resize, cambia el tamaño de las imágenes\n",
    "#     - ToTensor, convierte un grupo de imágenes a un tensor\n",
    "#     - Normalize, normaliza los colores de la imagen bajo ciertos parámetros\n",
    "\n",
    "# Existen otras transformaciones que pueden ayudar al entrenamiento de la red y dar la ventaja en la competencia.\n",
    "# Consultelas en https://pytorch.org/docs/stable/torchvision/transforms.html \n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Dividimos el dataset en training y test, es una parte fundamental para comprobar el comportamiento\n",
    "# de la red sobre datos que no ha visto durante el entrenamiento\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 50, 50])\n",
    "\n",
    "\n",
    "# Creamos dos 'cargadores de datos' los cuales producen grupos aleatorios de imágenes \n",
    "# y son cargados en paralelo para ser usados en el entrenamiento de la red.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "\n",
    "# DEFINIR EL MODELO DE RED NEURONAL\n",
    "# El paquete torchvision proporciona una colección de redes preentrenadas que podemos usar.\n",
    "# En un proceso llamado 'transferencia de aprendizaje' podemos cambiar el propósito de una red entrenada\n",
    "# sobre millones de imágenes y reusarlo para una tarea diferente.\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# La red Alexnet fue entrenada en un dataset con 1000 clases, pero nuestro dataset solo tiene 2 clases.\n",
    "# Por lo tanto debemos reemplazar la capa final de la red con una nueva capa con solo 2 salidas.\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "\n",
    "# ENTRENAR LA RED NEURONAL\n",
    "# Usando el código siguiente podemos entrenar la red neuronal por 30 EPOCHS y guardar el mejor modelo\n",
    "# después de cada EPOCH.\n",
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_model_floor.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        outputs = model(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Probar el Modelo\n",
    "\n",
    "Encendemos la JETBOT y accedemos por la IP mostrada en la PioLed y el puerto, como se enseñó en el manejo de comandos básicos.\n",
    "\n",
    "\n",
    "Pasamos el modelo entrenado desde Guane al equipo que estamos usando, y de este lo pasamos a la JETBOT.\n",
    "\n",
    "Abrimos un notebook en la JETBOT y cargamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos todos los paquetes necesarios\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Creamos el model de la red neuronal Alexnet, sin valores preentrenados\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "# Cargamos el modelo que entrenamos con nuestro dataset\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Pasamos el modelo a ejecución por GPU\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "# Es necesario transformar las imágenes tomadas por la cámara al formato de imágenes\n",
    "# usadas para entrenar la red neuronal.\n",
    "# Para esto creamos una función de preprocesamiento.\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "\n",
    "# Creamos un widget para acceder a la cámara\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(widgets.HBox([image]))\n",
    "\n",
    "\n",
    "# Creamos una instancia Robot y conectamos:\n",
    "#    - la imagen de la camara\n",
    "#    - la red neuronal\n",
    "#    - los movimientos del robot\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "\n",
    "def update(change):\n",
    "    global robot\n",
    "    # Imagen de la cámara, es pasada a la red neuronal\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # Aplicamos la función 'softmax' para normalizar el vector de salida de la red neuronal\n",
    "    # Todos los valores suman a 1, convirtiendo esta salida en una distribución de probabilidad\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    # Obtenemos la probabilidad que el robot esté bloqueado del primer elemento del vector\n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    # Si la red considera que hay una probabilidad menor al 50% de estar bloqueado, avanzamos\n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(0.3)\n",
    "    else:\n",
    "    # Si está bloqueado, el robot gira a la izquierda\n",
    "        robot.left(0.3)\n",
    "    \n",
    "    # Esperamos 1 milisegundo antes de la siguiente decisión\n",
    "    time.sleep(0.1)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>ADVERTENCIA #1: </font>** LOS SIGUIENTES COMANDOS MUEVEN EL ROBOT, ASEGURESE QUE EL ROBOT TIENE ESPACIO LIBRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos la función una vez para inicializar\n",
    "update({'new': camera.value})\n",
    "\n",
    "# Enlazamos la función 'update' a el valor de la camara\n",
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para detener el robot en cualquier momento, ejecute las siguientes celdas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si quiere cambiar el comportamiento del robot, desvincule la función 'update', detenga el vehiculo y haga los cambios.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Mejorar\n",
    "\n",
    "El mejoramiento continuo es una característica fundamental en un proyecto de inteligencia artificial, para este proyecto se sugieren dos aspectos para mejorar el comportamiento del vehículo autónomo.\n",
    "\n",
    "1. **DATOS:** Analice el comportamiento del vehículo y los fallos que presenta, adquiera más imágenes que permitan al robot evitar estos errores. Añada las imágenes al dataset y entrene un nuevo modelo.\n",
    "\n",
    "\n",
    "2. **MOVIMIENTOS:** Según el nivel de bloqueo que reporta la red neuronal (de 0 a 1) otra variedad y combinación de movimientos puede mejorar el comportamiento del vehículo sobre la pista.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
