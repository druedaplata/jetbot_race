{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Conociendo la JETBOT\n",
    "\n",
    "<img src=\"images/jetbot.jpeg\" width=50%>\n",
    "\n",
    "1. Jetson Nano, dispositivo de cómputo de bajo consumo con GPU integrada.\n",
    "\n",
    "\n",
    "2. Camara, que servirá de entrada a la aplicación.\n",
    "\n",
    "\n",
    "3. PioLed, que muestra información del sistema operativo y la ip del equipo (parte de atrás).\n",
    "\n",
    "\n",
    "4. Motores independientes para el movimiento de las llantas.\n",
    "\n",
    "\n",
    "5. Batería de 10000 mAH, 5V y un puerto usb3.0 de 3A, y un usb2.0 de 2A.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Encender el Equipo\n",
    "\n",
    "1. Inserte la microSD con el sistema operativo en la Jetson Nano o asegurese que ya está puesta.\n",
    "\n",
    "\n",
    "2. Conecte el motor y la Jetson Nano a los puertos usb de la batería.\n",
    "\n",
    "    <table>\n",
    "      <tr>\n",
    "          <td><img src=\"images/j1.jpeg\" width=50%></td>\n",
    "          <td><img src=\"images/j2.jpeg\"></td>\n",
    "      </tr>\n",
    "    </table>\n",
    "    \n",
    "\n",
    "2. Espere a que la PioLed encienda e ingrese a la dirección mostrada y el puerto 8888.\n",
    "\n",
    "    - Por ejemplo, 192.168.1.13:8888\n",
    "    - La contraseña es *jetbot*\n",
    "    \n",
    "    \n",
    "3. Al encender la jetbot un servicio de notebook es lanzado automáticamente, abra un nuevo *notebook* en la jetbot y siga las instrucciones de movimientos básicos.\n",
    "\n",
    "<img src=\"images/j3.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Movimientos Básicos\n",
    "\n",
    "La JetBot tiene 5 acciones básicos para el control del equipo:\n",
    "\n",
    "1. forward, mover hacia adelante.\n",
    "2. backward, mover hacia atrás.\n",
    "3. left, girar a la izquierda.\n",
    "4. right, girar a la derecha.\n",
    "5. stop, detener el motor.\n",
    "\n",
    "Para acceder a estos movimientos es necesario importar la clase Robot desde Jetbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una instancia de la clase Robot, para acceder a todos los movimientos básicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Manejar el robot\n",
    "\n",
    "# **<font color='red'>ADVERTENCIA #1: </font>** \n",
    "LOS SIGUIENTES COMANDOS MUEVEN EL ROBOT, ASEGURESE QUE EL ROBOT TIENE ESPACIO LIBRE.\n",
    "\n",
    "\n",
    "# **<font color='red'>ADVERTENCIA #2: </font>** \n",
    "\n",
    "EL ROBOT ES MUY RÁPIDO, SIEMPRE ASEGURESE DE AJUSTAR LA VELOCIDAD SOLO AL 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El robot gira hacia la izquierda sin detenerse\n",
    "robot.left(speed=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos detener el robot\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos que el robot se mueva solo por poco tiempo podemos usar la función **sleep** del paquete **time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.right(speed=0.3)\n",
    "time.sleep(2)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinando los movimientos básicos y la función **sleep**, podemos generar movimientos mas complejos para el movimiento del carro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_turn():\n",
    "    robot.left(speed=0.3)\n",
    "    time.sleep(2)\n",
    "    robot.forward(speed=0.3)\n",
    "    time.sleep(2)\n",
    "    robot.stop()\n",
    "    \n",
    "u_turn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceder a la cámara\n",
    "\n",
    "Podemos acceder a la cámara usando otras Clases que proporciona JETBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "# Creamos una instancia de la cámara, para acceder a esta.\n",
    "camera = Camera.insance(width=224, height=224)\n",
    "# Creamos una 'imagen' en notebook para mostrar lo que observa la cámara\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "# Enlazamos la información de la cámara con la imagen creada\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "# Mostramos la imagen en el notebook\n",
    "display(widgets.HBox([image]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimente por un tiempo con los comandos básicos, y apague la JetBot para ahorrar energía.\n",
    "\n",
    "Pidale ayuda a un instructor si hay algún problema.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "<img src=\"images/dl_context.png\" width=70%>\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<img src=\"images/ml_vs_dl.png\">\n",
    "\n",
    "---\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![SegmentLocal](images/neural_net.gif \"neural network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los métodos de Deep Learning apuntan a aprender características jerárquicas, donde las características de alto nivel están formadas por la composición de características de bajo nivel.\n",
    "\n",
    "<img src=\"images/cnn_feature_hierarchy.png\">\n",
    "\n",
    "\n",
    "Cada una de las neuronas presentes en una red neuronal funciona de la siguiente manera:\n",
    "\n",
    "1. Recibe unas entradas $X_i$, que pueden ser los valores de un grupo de pixeles.\n",
    "\n",
    "\n",
    "2. Cada entrada $X_i$ es multiplicada por un peso $W_i$, estos pesos se aprenden durante el entrenamiento de la red.\n",
    "\n",
    "\n",
    "3. Todas las multiplicaciones son sumadas $\\sum^n_{i=1}X_iW_i$\n",
    "\n",
    "\n",
    "4. Al resultado de esta suma se le aplica una función de activación, y es pasada como una entrada a la siguiente capa en la red neuronal.\n",
    "\n",
    "![neuron](images/neuron.png \"neuron\")\n",
    "\n",
    "\n",
    "Si ampliamos esta operación a redes neuronales muy profundas y con gran cantidad de neuronas por cada capa, el número de operaciones de multiplicación y suma aumenta exponencialmente, pero podemos destacar unas características clave.\n",
    "\n",
    "\n",
    "* Las operaciones dentro de la red son muy simples (sumas y multipliaciones)\n",
    "\n",
    "\n",
    "* Todas las operaciones en cada una de las capas son independientes.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Las GPU y Deep Learning\n",
    "\n",
    "![cpu_gpu_1](images/cpu_gpu_1.png)\n",
    "\n",
    "![cpu_gpu_1](images/cpu_gpu_2.png)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### La cantidad de imágenes y Deep Learning \n",
    "\n",
    "Los algoritmos de Deep Learning necesitan una gran cantidad de imágenes, debido a la enorme cantidad de parámetros que tienen.\n",
    "\n",
    "\n",
    "<img src=\"images/dl.png\" width=70%>\n",
    "  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Razones para la popularidad del Deep Learning\n",
    "\n",
    "### 1. Aparición de enormes conjuntos de datos etiquetados.\n",
    "\n",
    "- Clasificación: [IMAGENET](http://image-net.org/)\n",
    "\n",
    "- Detección y Segmentación: [Microsoft COCO](http://cocodataset.org/#home)\n",
    "\n",
    "<img src=\"images/datasets_sample.jpeg\">\n",
    "\n",
    "### 2. Computación masivamente paralela con GPUs.\n",
    "\n",
    "ILSVRC = Imagenet Large Scale Visual Recognition Competition\n",
    "\n",
    "<img src=\"images/imagenet_progress.png\">\n",
    "\n",
    "### 3. Desarrollo de Frameworks de DL.\n",
    "\n",
    "Para la competencia usaremos el framework Pytorch\n",
    "\n",
    "<img src=\"images/dl_frameworks.jpg\" width=70%>\n",
    "\n",
    "### 4. Investigación en arquitecturas de redes neuronales y funciones de activación.\n",
    "\n",
    "Para la competencia usaremos Alexnet\n",
    "\n",
    "<img src=\"images/dl_architectures.png\" width=70%>\n",
    "\n",
    "\n",
    "AlexNet tiene:\n",
    "\n",
    "- 660.000 neuronas\n",
    "- 61 Millónes de parámetros\n",
    "- 600 Millones de conexiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Flujo de Trabajo de un proyecto en Deep Learning\n",
    "\n",
    "<img src=\"images/dl_workflow.jpeg\">\n",
    "\n",
    "Fuente: [WTF is Machine Learning?](https://towardsdatascience.com/wtf-is-machine-learning-a-quick-guide-39457e49c65b)\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "## Ejemplo: Evitar Colisiones con la JetBot\n",
    "\n",
    "Vamos a intentar resolver este problema usando deep learning, la jetson nano y el sensor de la cámara.\n",
    "\n",
    "\n",
    "### Paso 1: Obtener Datos\n",
    "\n",
    "El robot está limitado a la información que obtiene desde la camara, desde este punto de vista necesitamos crear una \"burbuja de seguridad\" al rededor del robot, para evitar que entre en escenarios donde se golpee.\n",
    "\n",
    "Tenemos entonces dos estados para el robot:\n",
    "\n",
    "1. **blocked:** El robot tiene algún obstaculo de frente por lo cual debe girar y buscar otro camino.\n",
    "\n",
    "2. **free:** El robot puede avanzar libremente.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/free.jpeg\"></td>\n",
    "        <td><img src=\"images/blocked.jpeg\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "**<font color='green'>RECOMENDACIÓN #1: </font>** Tome videos con el celular teniendo en cuenta la perspectiva del robot, para ambos estados. Recuerde las dimensiones del robot y los diferentes obstaculos que puede tener (puertas, sillas, zapatos, otros jetbot).\n",
    "\n",
    "**<font color='green'>RECOMENDACIÓN #2: </font>** Tome video donde el camino este libre todo el tiempo, tome videos cortos donde el camino esté bloqueado todo el tiempo, trate de no mezclar los dos casos para que sea mas fácil crear el dataset de imágenes.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paso 2: Limpiar, preparar y manipular los datos.\n",
    "\n",
    "Una vez terminada la obtención de los videos, es necesario crear el dataset de imágenes en los dos estados que tiene nuestro equipo. Para obtener las imágenes que usaremos para el entrenamiento necesitamos separar los **frames** de los videos y guardarlas en imágenes.\n",
    "\n",
    "1. **Cree un directorio llamado 'dataset' y en este dos subdirectorios llamados 'blocked' y 'free'.**\n",
    "\n",
    "Extraiga las imágenes de los videos con el siguiente comando y guardelas en los respectivos directorios, según su criterio.\n",
    "\n",
    "```bash\n",
    "ffmpeg -i video.mp4 img_%04d.jpg -hide_banner\n",
    "```\n",
    "\n",
    "2. **Entre a la página del [Centro de Supercomputación](http://www.sc3.uis.edu.co/) y en la pestaña 'SERVICIOS' seleccione 'JUPYTERHUB'.**\n",
    "\n",
    "    - Ingrese con su nombre de usuario/contraseña y reserve un notebook con 1 core por 1 hora.\n",
    "    \n",
    "    - Suba la carpeta 'dataset' al cluster de Guane en su /home de estudiante. Consulte con un instructor si tiene dudas.\n",
    "   \n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paso 3: Entrenar el modelo\n",
    "\n",
    "1. Cree un nuevo notebook en blanco, que usaremos para entrenar el modelo.\n",
    "\n",
    "\n",
    "2. Copie el código en la siguiente celda al notebook de Guane para entrenar el modelo.\n",
    "\n",
    "\n",
    "3. Analice los comentarios y los objetos creados para el entrenamiento de la red neuronal.\n",
    "\n",
    "Usaremos el framework *Pytorch* para entrenar el modelo para nuestras dos clases (blocked, free).\n",
    "\n",
    "**<font color='green'>RECOMENDACIÓN #3: </font>** Entender este código puede darles una gran ventaja en la competencia.\n",
    "\n",
    "\n",
    "**<font color='BLUE'>Discusión: </font>** Responda en su grupo las siguientes preguntas, mirando el código o Google.\n",
    "\n",
    "- Cuantas lineas de código son usadas para crear la red Alexnet?\n",
    "\n",
    "\n",
    "- Cómo ingresan las imágenes a la red? \n",
    "\n",
    "\n",
    "- Cuál es la función de los objetos 'dataset', 'train_dataset' y 'train_loader'?\n",
    "\n",
    "\n",
    "- Por qué dividimos el dataset en Train y Test? Cuantas imágenes tiene test_dataset? Son suficientes?\n",
    "\n",
    "\n",
    "- Qué es una EPOCH?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el framework y las utilidades necesarias\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Creamos la instancia 'dataset' para acceder a las imágenes,\n",
    "# Componemos una secuencia de transformaciones para virtualmente aumentar la cantidad de los datos.\n",
    "#     - ColorJitter, modifica la luz, contraste e iluminación de la imagen por un porcentaje.\n",
    "#     - Resize, cambia el tamaño de las imágenes\n",
    "#     - ToTensor, convierte un grupo de imágenes a un tensor\n",
    "#     - Normalize, normaliza los colores de la imagen bajo ciertos parámetros\n",
    "\n",
    "# Existen otras transformaciones que pueden ayudar al entrenamiento de la red y dar la ventaja en la competencia.\n",
    "# Consultelas en https://pytorch.org/docs/stable/torchvision/transforms.html \n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "# Dividimos el dataset en training y test, es una parte fundamental para comprobar el comportamiento\n",
    "# de la red sobre datos que no ha visto durante el entrenamiento\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 50, 50])\n",
    "\n",
    "\n",
    "# Creamos dos 'cargadores de datos' los cuales producen grupos aleatorios de imágenes \n",
    "# y son cargados en paralelo para ser usados en el entrenamiento de la red.\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "\n",
    "# DEFINIR EL MODELO DE RED NEURONAL\n",
    "# El paquete torchvision proporciona una colección de redes preentrenadas que podemos usar.\n",
    "# En un proceso llamado 'transferencia de aprendizaje' podemos cambiar el propósito de una red entrenada\n",
    "# sobre millones de imágenes y reusarlo para una tarea diferente.\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# La red Alexnet fue entrenada en un dataset con 1000 clases, pero nuestro dataset solo tiene 2 clases.\n",
    "# Por lo tanto debemos reemplazar la capa final de la red con una nueva capa con solo 2 salidas.\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "\n",
    "# ENTRENAR LA RED NEURONAL\n",
    "# Usando el código siguiente podemos entrenar la red neuronal por 30 EPOCHS y guardar el mejor modelo\n",
    "# después de cada EPOCH.\n",
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_model_floor.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        outputs = model(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Probar el Modelo\n",
    "\n",
    "1. Encendemos la JETBOT y accedemos por la IP mostrada, como se indicó en el manejo de comandos básicos.\n",
    "\n",
    "\n",
    "2. Copiamos el modelo entrenado desde el cluster de Guane a un directorio de trabajo en la JETBOT.\n",
    "\n",
    "\n",
    "3. Abrimos un notebook en la JETBOT, en el mismo directorio donde se encuentra el modelo.\n",
    "\n",
    "\n",
    "4. Copiamos el código en la siguiente celda a el notebook en la JETBOT.\n",
    "\n",
    "\n",
    "5. Antes de ejecutar, analice el código en la celda y responda las siguientes preguntas:\n",
    "\n",
    "\n",
    "\n",
    "- ¿Cómo se está cargando el modelo entrenado por nosotros?\n",
    "    \n",
    "    \n",
    "- ¿Cómo se enlaza la imagen de la cámara, para que sirva de entrada a la red neuronal?\n",
    "    \n",
    "    \n",
    "- ¿Qué es la salida de la red neuronal, y qué hacemos con este valor?\n",
    "    \n",
    "    \n",
    "- ¿Donde se están dando las ordenes para el movimiento del carro?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRIMERA ETAPA\n",
    "\n",
    "1. Cargamos el modelo entrenado sobre una red Alexnet\n",
    "\n",
    "\n",
    "2. Pasamos la ejecución del modelo a la GPU que tiene la Jetson Nano\n",
    "\n",
    "\n",
    "3. Creamos una función para procesar las imágenes, teniendo en cuenta que las imágenes del celular que usamos para entrenar y las que ve la cámara son diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos todos los paquetes necesarios\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Creamos el model de la red neuronal Alexnet, sin valores preentrenados\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "# Cargamos el modelo que entrenamos con nuestro dataset\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Pasamos el modelo a ejecución por GPU\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "# Es necesario transformar las imágenes tomadas por la cámara al formato de imágenes\n",
    "# usadas para entrenar la red neuronal.\n",
    "# Para esto creamos una función de preprocesamiento.\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGUNDA ETAPA\n",
    "\n",
    "1. Accedemos a la cámara y la mostramos en pantalla, ejecute la celda de acceso a la cámara solo una vez para evitar errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creamos un widget para acceder a la cámara\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "display(widgets.HBox([image]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Definimos la función `update` donde se obtiene la salida de la red neuronal, y con esta información decidimos los movimientos del vehículo.\n",
    "\n",
    "3. Enlazamos la función `update` con la cámara para que se actualice cuando existan cambios en la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancia Robot y conectamos:\n",
    "#    - la imagen de la camara\n",
    "#    - la red neuronal\n",
    "#    - los movimientos del robot\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "\n",
    "def update(change):\n",
    "    global robot\n",
    "    # Imagen de la cámara, es pasada a la red neuronal\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # Aplicamos la función 'softmax' para normalizar el vector de salida de la red neuronal\n",
    "    # Todos los valores suman a 1, convirtiendo esta salida en una distribución de probabilidad\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    # Obtenemos la probabilidad que el robot esté bloqueado del primer elemento del vector\n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    # Si la red considera que hay una probabilidad menor al 50% de estar bloqueado, avanzamos\n",
    "    if prob_blocked < 0.5:\n",
    "        robot.forward(0.3)\n",
    "    else:\n",
    "    # Si está bloqueado, el robot gira a la izquierda\n",
    "        robot.left(0.3)\n",
    "    \n",
    "    # Esperamos 1 milisegundo antes de la siguiente decisión\n",
    "    time.sleep(0.1)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **<font color='red'>ADVERTENCIA #3: </font>** LOS SIGUIENTES COMANDOS MUEVEN EL ROBOT, ASEGURESE QUE EL ROBOT TIENE ESPACIO LIBRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos la función una vez para inicializar\n",
    "update({'new': camera.value})\n",
    "\n",
    "# Enlazamos la función 'update' a el valor de la camara\n",
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si quiere cambiar el comportamiento del robot, desvincule la función 'update', detenga el vehiculo y haga los cambios.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para detener el robot en cualquier momento, ejecute las siguientes celdas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Paso 5: Mejorar\n",
    "\n",
    "El mejoramiento continuo es una característica fundamental en un proyecto de inteligencia artificial, para este proyecto se sugieren dos aspectos para mejorar el comportamiento del vehículo autónomo.\n",
    "\n",
    "1. **DATOS:** Analice el comportamiento del vehículo y los fallos que presenta, adquiera más imágenes que permitan al robot evitar estos errores. Añada las imágenes al dataset y entrene un nuevo modelo.\n",
    "\n",
    "\n",
    "2. **MOVIMIENTOS:** Según el nivel de bloqueo que reporta la red neuronal (de 0 a 1) otra variedad y combinación de movimientos puede mejorar el comportamiento del vehículo sobre la pista.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
